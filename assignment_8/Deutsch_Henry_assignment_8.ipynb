{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84GqNz8Ztw4G"
   },
   "source": [
    "# Artificial Intelligence\n",
    "# 464/664\n",
    "# Assignment #8\n",
    "\n",
    "## General Directions for this Assignment\n",
    "\n",
    "00. We're using a Jupyter Notebook environment (tutorial available here: https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html),\n",
    "01. Output format should be exactly as requested (it is your responsibility to make sure notebook looks as expected on Gradescope),\n",
    "02. Check submission deadline on Gradescope,\n",
    "03. Rename the file to Last_First_assignment_8,\n",
    "04. Submit your notebook (as .ipynb, not PDF) using Gradescope, and\n",
    "05. Do not submit any other files.\n",
    "\n",
    "## Before You Submit...\n",
    "\n",
    "1. Re-read the general instructions provided above, and\n",
    "2. Hit \"Kernel\"->\"Restart & Run All\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSN1KpKJtw4K"
   },
   "source": [
    "## Language Modeling\n",
    "\n",
    "This homework will require you to load and train models.  If you choose small models and datasets, you should be able to run this locally on your computer. However, larger models/datasets may require GPU access. You can access one GPU for free on [Google Colab](https://colab.research.google.com/).\n",
    "\n",
    "We will use HuggingFace libraries in this assignment. We discussed majority of what you will need during the discussion demo. Additional documentation can be found [here](https://huggingface.co/docs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (0.4.1)\n",
      "Requirement already satisfied: multiprocess in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from evaluate) (4.62.3)\n",
      "Requirement already satisfied: responses<0.19 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from evaluate) (1.19.5)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from evaluate) (2023.1.0)\n",
      "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from evaluate) (0.16.4)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from evaluate) (1.3.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from evaluate) (2.26.0)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from evaluate) (21.0)\n",
      "Requirement already satisfied: importlib-metadata in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from evaluate) (4.8.1)\n",
      "Requirement already satisfied: dill in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from evaluate) (2.13.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate) (12.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate) (3.8.6)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from packaging->evaluate) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (1.26.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from importlib-metadata->evaluate) (3.5.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas->evaluate) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.13.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (21.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (4.30.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from transformers) (2024.4.16)\n",
      "Requirement already satisfied: importlib-metadata in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from transformers) (4.8.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.5.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests->transformers) (2021.5.30)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (4.62.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install evaluate\n",
    "%pip install transformers\n",
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3-RPRoiXtw4L"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, AutoModelForCausalLM\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeaSsuWCt2dI"
   },
   "source": [
    "## Problem 0: Data\n",
    "From the [HuggingFace Datasets](https://huggingface.co/datasets), choose a dataset that satisfies the following criteria:\n",
    "- Data must have train and test splits (Optional development set)\n",
    "- Task must be text classification\n",
    "- Task must have at least 3 labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WaYqkeqQyanB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/Users/Henry/.cache/huggingface/datasets/parquet/ag_news-9af2a5926861d22a/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n",
      "100%|██████████| 2/2 [00:00<00:00, 81.58it/s]\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"ag_news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Describe the data.</h1>\n",
    "What is the utility of the task? What are the inputs? What are the labels? Are the any potential difficulties you expect from the task? How do you evaluate the performance of this task?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is a collection of headlines from news articles, classified into one of 4 categories: World, Sports, Business, or Science/Technology. Inputs are the headlines, outputs are the categories.\n",
    "\n",
    "I think it's conceiveable that a few things could cause the BERT and gpt2 models trouble. Firstly, there is some amount of ambiguity of the labels themselves — I'm not sure if there are headlines in the dataset that sit at the intersection of categories.\n",
    "\n",
    "Also, I'm not sure how much domain-specific knowledge gpt2 has, and it may need to know some medical technology or business terminology to classify correctly.\n",
    "\n",
    "And for gpt-2 in particular, we have the extra difficulty of parsing the response correctly, in addition to the main task of classifying the headline. \n",
    "\n",
    "I think evaluating performance should be pretty straight forward, we can just see what percentage of time it classifies the headline correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Research current methods using this dataset.</h1>\n",
    "What is the current state of the art method? Describe the method, including the type of model used, training protocol (if any), and the performance. Cite your sources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current state of the art is XLNet, an autoregressive Transformer model, which gets an error rate of ~4.45%. Like BERT models, XLNet has \"bidirectional context learning,\" which means it tries to predict the text both forwards and backwards, allowing it to learn more context. \n",
    "\n",
    "It has some differences to BERT models as well. It doesn't mask tokens and try to predict them, like BERT does, but instead looks at words in different orders and tries to predict different orders. XLNet also has some sort of special memory system to allow it to better remember connected words far apart from each other.\n",
    "\n",
    "However, the runner up is a BERT model, BERT-ITPT-FiT, which also does very well w/ an error rate of ~4.8%.\n",
    "\n",
    "Sources\n",
    "- https://paperswithcode.com/sota/text-classification-on-ag-news\n",
    "- https://rbcborealis.com/research-blogs/understanding-xlnet/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) If necessary, perform any data preprocessing here. For example, depending on the dataset you choose, you may need to clean the text or split the training set into a train and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into test and training\n",
    "train_test_split = ds[\"train\"].train_test_split(test_size=0.2)\n",
    "train_ds = train_test_split[\"train\"]\n",
    "test_ds = train_test_split[\"test\"]\n",
    "\n",
    "# get a smaller subset so it doesn't take forever on my 2020 base model macbook:\n",
    "train_subset = train_ds.select(range(10000))  # 10k examples\n",
    "test_subset = test_ds.select(range(1000))    # 1k examples\n",
    "\n",
    "label_to_category = {\n",
    "  0: \"World\",\n",
    "  1: \"Sports\",\n",
    "  2: \"Business\",\n",
    "  3: \"Science/Technology\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Encoder only models\n",
    "Choose an encoder only model (e.g. BERT). Load the model and add a classification layer. \n",
    "\n",
    "Describe the model you choose. What are the unique properties of this model? What are the pros and cons? Cite your sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose the **RoBERTa** model (Robustly Optimized BERT Approach). It's a bigger model (160GB vs 16GB w/ BERT) and goes through more training, but has a few improvements as well:\n",
    "- No next sentence prediction: removes BERT's NSP task, \n",
    "- Dynamic Masking: Applies a diffrent masking pattern to the training data than the test data.\n",
    "- No Next sentence prediction: removes BERT's NSP task, and focuses on masked language modeling instead.\n",
    "\n",
    "Pros:\n",
    "RoBERTa beats the performance of BERT on most benchmarks, and is considered one of the state of the art models. It apparently handles out-of-vocabulary words (words that are not in the training set) better than BERT. It does well on classification tasks.\n",
    "\n",
    "Cons:\n",
    "Because of the size of the model, it's more computationally expensive to train as you might expect, and takes longer. It has a slower \"inference time\", which means it takes longer to get the output. The added size and complexity might make it overkill for some projects.\n",
    "\n",
    "Sources:\n",
    "- https://www.geeksforgeeks.org/overview-of-roberta-model/\n",
    "- https://huggingface.co/FacebookAI/roberta-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████| 313/313 [01:50<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average training loss: 0.4467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   3%|▎         | 1/32 [00:00<00:03,  8.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 0\n",
      "\n",
      "Text: skype available for mac os x skype technologies sa has launched the beta version of skype for mac os x. the software can be downloaded for free and is available immediately.\n",
      "Predicted: Science/Technology\n",
      "True label: Science/Technology\n",
      "\n",
      "Text: russia confirms plane crash terror link a widely - suspected terrorist connection became an official claim when russian authorities said they found traces of explosives in the wreckage of one of two passenger jets that crashed almost simultaneously, killing all 90 people on board.\n",
      "Predicted: World\n",
      "True label: World\n",
      "\n",
      "Text: falmouth blanks dartmouth the 10th - ranked dartmouth boys'soccer team had given up only one goal this season, but yesterday, host falmouth scored two to hand the indians their first loss, 2 - 0.\n",
      "Predicted: Sports\n",
      "True label: Sports\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  72%|███████▏  | 23/32 [00:01<00:00, 13.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 20\n",
      "\n",
      "Text: southwest bids \\ $ 117m for ata assets southwest airlines # 39 ; package of \\ $ 117 million in cash, loan payoffs and preferred stock purchases was selected as the winning bid at the bankruptcy court - approved auction for certain ata airlines inc.\n",
      "Predicted: Business\n",
      "True label: Business\n",
      "\n",
      "Text: security expert warns internet pharmacies at risk from terrorists ( canadian press ) canadian press - toronto ( cp ) - a canadian - based security expert will tell a panel on internet pharmacies this week that mail - order drug companies could become targets for terrorists.\n",
      "Predicted: Science/Technology\n",
      "True label: World\n",
      "\n",
      "Text: sec may act against ex - lucent ceo lucent technologies inc. said monday that three of its former employees have been notified by the securities and exchange commission that regulators are considering recommending civil action against them.\n",
      "Predicted: Business\n",
      "True label: Business\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 32/32 [00:02<00:00, 13.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|██████████| 313/313 [01:31<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average training loss: 0.1929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   6%|▋         | 2/32 [00:00<00:02, 12.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 0\n",
      "\n",
      "Text: skype available for mac os x skype technologies sa has launched the beta version of skype for mac os x. the software can be downloaded for free and is available immediately.\n",
      "Predicted: Science/Technology\n",
      "True label: Science/Technology\n",
      "\n",
      "Text: russia confirms plane crash terror link a widely - suspected terrorist connection became an official claim when russian authorities said they found traces of explosives in the wreckage of one of two passenger jets that crashed almost simultaneously, killing all 90 people on board.\n",
      "Predicted: World\n",
      "True label: World\n",
      "\n",
      "Text: falmouth blanks dartmouth the 10th - ranked dartmouth boys'soccer team had given up only one goal this season, but yesterday, host falmouth scored two to hand the indians their first loss, 2 - 0.\n",
      "Predicted: Sports\n",
      "True label: Sports\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  69%|██████▉   | 22/32 [00:01<00:00, 13.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 20\n",
      "\n",
      "Text: southwest bids \\ $ 117m for ata assets southwest airlines # 39 ; package of \\ $ 117 million in cash, loan payoffs and preferred stock purchases was selected as the winning bid at the bankruptcy court - approved auction for certain ata airlines inc.\n",
      "Predicted: Business\n",
      "True label: Business\n",
      "\n",
      "Text: security expert warns internet pharmacies at risk from terrorists ( canadian press ) canadian press - toronto ( cp ) - a canadian - based security expert will tell a panel on internet pharmacies this week that mail - order drug companies could become targets for terrorists.\n",
      "Predicted: World\n",
      "True label: World\n",
      "\n",
      "Text: sec may act against ex - lucent ceo lucent technologies inc. said monday that three of its former employees have been notified by the securities and exchange commission that regulators are considering recommending civil action against them.\n",
      "Predicted: Business\n",
      "True label: Business\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 32/32 [00:02<00:00, 13.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8960\n",
      "Training completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"prajjwal1/bert-tiny\"  # tiny BERT - 4.4M parameters as opposed to 110M\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# load the model and add a classification layer w/ 4 labels\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4)\n",
    "\n",
    "# tokenize data\n",
    "train_encodings = tokenizer(train_subset['text'], truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(test_subset['text'], truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# create torch datasets\n",
    "class NewsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = NewsDataset(train_encodings, train_subset['label'])\n",
    "test_dataset = NewsDataset(test_encodings, test_subset['label'])\n",
    "\n",
    "# create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# training setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4)  # Higher learning rate for faster training\n",
    "print(f\"Training on {device}\")\n",
    "\n",
    "# training loop\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    # training\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"\\nAverage training loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # evaluation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(test_loader, desc=\"Evaluating\")):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            predictions = outputs.logits.argmax(-1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # print every 20th batch\n",
    "            if i % 20 == 0:\n",
    "                print(f\"\\nBatch {i}\")\n",
    "                # get the text for the first 3 examples in batch\n",
    "                texts = tokenizer.batch_decode(input_ids[:3], skip_special_tokens=True)\n",
    "                for j in range(len(texts)):\n",
    "                    print(\"\\nText:\", texts[j])  # First 100 chars of text\n",
    "                    print(f\"Predicted: {label_to_category[predictions[j].item()]}\")\n",
    "                    print(f\"True label: {label_to_category[labels[j].item()]}\")\n",
    "                print(\"-------------------\")\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Decoder only models\n",
    "Choose an decoder only model (e.g. GPT2). Describe the model you choose. What are the unique properties of this model? What are the pros and cons? Cite your sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose the GPT-2 model. It's a transformer based decoder-only model. It's a smaller model than BERT, and also faster and easier to train.\n",
    "\n",
    "Both GPT-2 and BERT use a transformer architecture with self-attention mechanisms. GPT-2 predicts next-tokens in sequence, as opposed to BERT, which predicts masked tokens. This means GPT-2 lends itself more to text generation and completion, because of this more sequential generation. BERT tends to do better in classification tasks, like sentiment analysis, though. \n",
    "\n",
    "GPT-2 is also a pretty small model, so it's faster and easier to train. It has good zero-few shot capabilities, while BERT tends to require fine tuning to get acceptable performance.\n",
    "\n",
    "Sources:\n",
    "- https://huggingface.co/gpt2\n",
    "- https://en.wikipedia.org/wiki/GPT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model and use prompting for your task. You will likely need to write a helper function to parse the answer. \n",
    "\n",
    "(Ex. “The answer is 1” -> 1). Report the performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:00<01:23,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: Skype available for Mac OS X Skype Technologies SA has launched the beta version of Skype for Mac OS X. The software can be downloaded for free and is available immediately.\n",
      "True: Science/Technology\n",
      "Predicted: Business\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:08<01:10,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: Indians Pitcher Shot _ Cleveland pitcher Kyle Denney was slightly wounded in the leg late last night, on the team bus as it left Kauffman Stadium for Kansas City International Airport.\n",
      "True: Sports\n",
      "Predicted: Sports\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:16<00:58,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: Ex-minister hurt in Beirut blast A bomb has gone off in the Lebanese capital Beirut, injuring a former minister and killing his driver.\n",
      "True: World\n",
      "Predicted: World\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [00:24<00:58,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: New Program Lets People Design 3-D Objects Programs for computer-aided design, or CAD, have been around for decades, but eMachineShop.com appears to be the first service that checks whether a design can be made, tells the customer how much it will cost. If the customer wants the item the design goes to a \"real world\" machine shop for manufacturing.\n",
      "True: Science/Technology\n",
      "Predicted: Unknown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [00:33<00:52,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: House GOP Leader DeLay Delights in Rebuke of Accuser (Reuters) Reuters - A Texas congressman who brought a\\successful ethics complaint against House Majority Leader Tom\\Delay was himself rebuked by the ethics panel for violating the\\rules in the way he brought the complaint.\n",
      "True: World\n",
      "Predicted: Business\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [00:41<00:41,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: Talks Continue After China Hostage Deadline Passes  CHAGMALAI, Pakistan (Reuters) - Islamic militants holding  two Chinese engineers hostage in Pakistan threatened to kill  one on Monday unless security forces ended a siege of their  hideout, a tactic the interior minister said had echoes of  Iraq.\n",
      "True: World\n",
      "Predicted: World\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [00:51<00:36,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: Exxon Mobil Profit Soars  NEW YORK (Reuters) - Exxon Mobil Corp. &lt;A HREF=\"http://www.investor.reuters.com/FullQuote.aspx?ticker=XOM.N target=/stocks/quickinfo/fullquote\"&gt;XOM.N&lt;/A&gt;, the world's  largest publicly traded oil company, on Thursday said quarterly  profit surged 56 percent, driven by soaring oil prices and  strong results from refining operations.\n",
      "True: Business\n",
      "Predicted: Business\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [01:00<00:27,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: France demands release of hostages France #39;s interior minister demanded Sunday the release of two French journalists believed kidnapped by Islamic militants in Iraq.\n",
      "True: World\n",
      "Predicted: Sports\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [01:08<00:15,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: Ferguson Offers Rooney Helping Hand Sir Alex Ferguson is confident he can keep Wayne Rooneys feet firmly on the ground despite his sensational Champions League debut.\n",
      "True: Sports\n",
      "Predicted: World\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 91/100 [01:18<00:08,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: Reds' Vander Wal Becomes Free Agent (AP) AP - Pinch-hitter John Vander Wal chose free agency Wednesday instead of a demotion off the Reds' 40-man roster.\n",
      "True: Sports\n",
      "Predicted: World\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:26<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 0.4900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# load GPT-2 model and tokenizer (using smallest version)\n",
    "model_name = \"gpt2\"  # or \"distilgpt2\" for even smaller model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# helper function to convert label to category\n",
    "def get_category(label):\n",
    "    categories = {\n",
    "        0: \"World\",\n",
    "        1: \"Sports\",\n",
    "        2: \"Business\",\n",
    "        3: \"Science/Technology\"\n",
    "    }\n",
    "    return categories[label]\n",
    "\n",
    "# helper function to parse GPT-2's response\n",
    "def parse_response(response):\n",
    "    response = response.lower().strip()\n",
    "    if \"world\" in response:\n",
    "        return 0\n",
    "    elif \"sport\" in response:\n",
    "        return 1\n",
    "    elif \"business\" in response:\n",
    "        return 2\n",
    "    elif \"science\" in response or \"tech\" in response:\n",
    "        return 3\n",
    "    else:\n",
    "        # print('BAD RESPONSE', response)\n",
    "        return -1  # Unable to parse\n",
    "\n",
    "# function to get prediction for a single text\n",
    "def get_prediction(text, model, tokenizer, device):\n",
    "    # create prompt\n",
    "    prompt = f\"Please classify this news article into one of these categories: World, Sports, Business, or Science/Technology. There are no other categories; you must pick one from that list.\\n\\nArticle: {text}\\n\\nCategory:\"\n",
    "    \n",
    "    # tokenize\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # generate response\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=10,\n",
    "            num_return_sequences=1,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            temperature=0.7\n",
    "        )\n",
    "    \n",
    "    # decode response\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response = response[len(prompt):]  # Remove the prompt from response\n",
    "    \n",
    "    # parse the response into a category\n",
    "    return parse_response(response)\n",
    "\n",
    "# test on a smaller subset\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Evaluating on {device}\")\n",
    "\n",
    "# use even smaller test set since generation is slower than classification\n",
    "test_subset = test_ds.select(range(100))\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for i in tqdm(range(len(test_subset))):\n",
    "    text = test_subset[i]['text']\n",
    "    true_label = test_subset[i]['label']\n",
    "    \n",
    "    pred_label = get_prediction(text, model, tokenizer, device)\n",
    "    \n",
    "    if pred_label == true_label:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "    \n",
    "    # print example predictions sometimes\n",
    "    if i % 10 == 0:\n",
    "        print(f\"\\nText: {text}\")\n",
    "        print(f\"True: {get_category(true_label)}\")\n",
    "        print(f\"Predicted: {get_category(pred_label) if pred_label != -1 else 'Unknown'}\")\n",
    "accuracy = correct / total\n",
    "print(f\"\\nTest accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Error Analysis\n",
    "\n",
    "Conduct an error analysis on both models. What is each model good at? What do they get wrong? Provide examples of both correct and incorrect predictions. Suggest methods to improve the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:39<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage decoded successfully: 0.9400\n",
      "Test accuracy: 0.4900\n",
      "Successfully decoded accuracy: 0.5213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'write'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sf/l0pbswk113vdp_mvkdpwnk9w0000gp/T/ipykernel_67881/2907420599.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Successfully decoded accuracy: {successfully_decoded_accuracy:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'True labels:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted labels:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/pprint.py\u001b[0m in \u001b[0;36mpprint\u001b[0;34m(object, stream, indent, width, depth, compact)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         compact=compact)\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/pprint.py\u001b[0m in \u001b[0;36mpprint\u001b[0;34m(self, object)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/pprint.py\u001b[0m in \u001b[0;36m_format\u001b[0;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobjid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0m_dispatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'write'"
     ]
    }
   ],
   "source": [
    "# Find what the error is for the gpt2 model among the responses we can accurately decode.\n",
    "correct = 0\n",
    "total_decoded = 0\n",
    "total = 0\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Evaluating on {device}\")\n",
    "for i in tqdm(range(len(test_subset))):\n",
    "    text = test_subset[i]['text']\n",
    "    true_label = test_subset[i]['label']\n",
    "    \n",
    "    pred_label = get_prediction(text, model, tokenizer, device)\n",
    "    \n",
    "    total += 1\n",
    "    if pred_label == -1: continue\n",
    "    if pred_label == true_label:\n",
    "        correct += 1\n",
    "    total_decoded += 1\n",
    "\n",
    "successfully_decoded_accuracy = correct / total_decoded\n",
    "total_accuracy = correct / total\n",
    "print(f\"Percentage decoded successfully: {total_decoded / total:.4f}\")\n",
    "print(f\"Test accuracy: {total_accuracy:.4f}\")\n",
    "print(f\"Successfully decoded accuracy: {successfully_decoded_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results I would periodically print in part 2, it was clear that GPT2 does not always give an easily decodable answer. To try to isolate the issue of answer parsing, I tracked the number of failed parsing attempts above, and found that the model gave interpretable answers 90% of the time. So the relatively poor performance of GPT2 seems to be largely some combination of the model and training, not the parsing.\n",
    "\n",
    "I'm aware that generative models sometimes tend to favor certain categories, so I printed the frequency of predictions, and the frequency of true labels. I found that the GPT 2 model did in fact have a big bias towards the earlier categories — it guessed category 0 61 times, and the second most popular guessed category (category 1) was only guessed 14 times. The last label was only guessed 7 times. Meanwhile, the true labels are pretty evenly distributed.\n",
    "\n",
    "GPT-2 example (Correct):\n",
    "> Text: Russia successfully launches Soyuz 2-1A rocket RBC, 09.11.2004, Moscow 09:25:54.Russia has   successfully launched a new model of booster rocket, the Soyuz-2-1A. The rocket blasted off at 9:30 pm from the Plesetsk launch pad carrying a satellite model.\n",
    "> True: Science/Technology\n",
    "> Predicted: Science/Technology\n",
    "\n",
    "GPT-2 example (Incorrect):\n",
    "> Text: Farmers  \"Cry Wolf\" Over Losses to Predators Sept. 23, 2004 - Cougars, wolves, lions and other predators inflict relatively few losses on livestock and farmers gain only a temporary boost if these marauders are culled, the British weekly New Scientist announced Wednesday....\n",
    "> True: Science/Technology\n",
    "> Predicted: World\n",
    "\n",
    "BERT example (Correct):\n",
    "> Text: bye - bye blueprint : 3d modeling catches on three - dimensional technology is changing the way buildings are designed and built - - but the industry will have to change, too.\n",
    "> Predicted: Science/Technology\n",
    "> True label: Science/Technology\n",
    "\n",
    "BERT example (Incorrect):\n",
    "> Text: man utd hopefuls face a rising challenge a successful bidder for manchester united could have to pay more than 300p a share, city sources suggested yesterday. the stock rose 13.\n",
    "> Predicted: Business\n",
    "> True label: Sports\n",
    "\n",
    "The GPT-2 incorrect example is a good representative example of how it tends to over-weight the world category in its answers. I didn't see any clear skewing in the incorrect BERT responses, but it didn't get many questions wrong. \n",
    "\n",
    "I think the best way to improve the performance of the GPT-2 model would be to train it on a larger dataset. I didn't train it on all that much data in this notebook because of the limitations of my laptop, but I think it would do much better if allowed to train on the full dataset. It is a much larger model (124M vs 4.4M for BERT), so it may need more data to accurately weight the larger model.\n",
    "\n",
    "For BERT, more epochs do not seem to improve performance a lot, so maybe the biggest improvements would come from architecture changes. For example, we could add a dropout layer to prevent overfitting by randomly dropping some percentage of connections each epoch. We could also add a learning rate scheduler to try to more smartly modulate the learning rate (generally make it smaller as the loss decreases). We could also implement gradient clipping to prevent the gradients from exploding and making the training unstable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL. BONUS. Problem 4: Improvements\n",
    "\n",
    "Implement your suggestions for improving the performance. You only need to implement improvements on one model (encoder-only or decoder-only). Describe your method and report the results on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to try to improve the BERT model, by adding the things discussed above: Added a dropout layer to prevent overfitting by randomly dropping some percentage of connections each epoch; added a learning rate scheduler to try to more smartly modulate the learning rate (generally make it smaller as the loss decreases); and implemented gradient clipping to prevent the gradients from exploding and making the training unstable.\n",
    "\n",
    "The results ended up being slightly better but pretty much the same as the original BERT model: .9090 vs .91 accuracy for old and new, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VfoAYAQtw4M"
   },
   "source": [
    "## Before You Submit...\n",
    "\n",
    "1. Re-read the general instructions provided above, and\n",
    "2. Hit \"Kernel\"->\"Restart & Run All\"."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "81px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
